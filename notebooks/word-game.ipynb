{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf60a06",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Building a Word Associations Game with Data Science and NLP\n",
    "\n",
    "The goal of this project is to explore how techniques from **Data Science** and **Natural Language Processing (NLP)** can be applied to create a **word associations game**.\n",
    "\n",
    "<img src=\"../assets/word-game.png\" alt=\"Game\" style=\"width: 800px;\"/>\n",
    "\n",
    "\n",
    "Along the way, we‚Äôll cover key NLP concepts such as:\n",
    "\n",
    "* Word embeddings\n",
    "* Embedding models\n",
    "* Training an embedding model (Word2Vec)\n",
    "* Calculating embedding similarity\n",
    "\n",
    "\n",
    "## Part A: Theory\n",
    "\n",
    "Before building the actual game, we need to understand the theory that powers it. The following section is adapted from my [blog post about vector databases](https://filip-melka.github.io/blog/posts/building-vector-db/).\n",
    "\n",
    "### Embeddings\n",
    "\n",
    "Let‚Äôs start with a simple example.\n",
    "\n",
    "Consider the four words:\n",
    "\n",
    "* ‚Äúman‚Äù\n",
    "* ‚Äúwoman‚Äù\n",
    "* ‚Äúboy‚Äù\n",
    "* ‚Äúgirl‚Äù\n",
    "\n",
    "Imagine plotting these words on a graph where the **x-axis** represents *gender* and the **y-axis** represents *age*. Each word would appear as a point in this 2D space.\n",
    "\n",
    "<img src=\"../assets/semantic-space.png\" alt=\"Semantic Space\" style=\"width: 800px;\"/>\n",
    "\n",
    "Here, *gender* and *age* act as **semantic features** ‚Äî numerical dimensions that capture part of each word‚Äôs meaning.\n",
    "\n",
    "Now, let‚Äôs add another word: ‚Äúking.‚Äù It‚Äôs similar in gender and age to ‚Äúman,‚Äù but clearly differs in meaning. To represent this distinction, we can introduce another semantic feature ‚Äî say, *royalty*.\n",
    "\n",
    "With this third axis, our words now live in a **3D semantic space**.\n",
    "\n",
    "<img src=\"../assets/coordinates.png\" alt=\"Coordinates\" style=\"width: 800px;\"/>\n",
    "\n",
    "Each word can now be represented by three numbers: *age*, *gender*, and *royalty*. This numerical representation ‚Äî a **vector** ‚Äî is what we call an **embedding**.\n",
    "\n",
    "Of course, three dimensions aren‚Äôt nearly enough to capture the richness of language. Real-world embedding models operate in **hundreds or even thousands of dimensions**. For example, OpenAI‚Äôs `text-embedding-3-large` model generates embeddings with **3,072 dimensions**.\n",
    "\n",
    "The real power of embeddings is that they allow us to **compare meanings mathematically**, just like we compare positions in physical space.\n",
    "\n",
    "### Measuring Similarity\n",
    "\n",
    "Once words are represented as vectors, we can measure how similar they are. Two common metrics are **Euclidean distance** and **cosine similarity**.\n",
    "\n",
    "#### Euclidean Distance\n",
    "\n",
    "Euclidean distance measures the ‚Äústraight-line‚Äù distance between two points in space. It‚Äôs intuitive and based on the Pythagorean theorem:\n",
    "\n",
    "<img src=\"../assets/pythagorean.png\" alt=\"Pythagorean theorem\" style=\"width: 800px;\"/>\n",
    "\n",
    "In Python, it can be calculated using `NumPy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d0a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(vector1, vector2):\n",
    "    return np.linalg.norm(vector1 - vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b51fcc",
   "metadata": {},
   "source": [
    "While intuitive, Euclidean distance is less effective in high-dimensional spaces, where the concept of ‚Äúdistance‚Äù becomes less meaningful. That‚Äôs why **cosine similarity** is often preferred for text embeddings.\n",
    "\n",
    "#### Cosine Similarity\n",
    "\n",
    "Cosine similarity measures the **angle** between two vectors, ignoring their magnitudes.\n",
    "\n",
    "In other words:\n",
    "\n",
    "* Euclidean distance asks, *‚ÄúHow far apart are these points?‚Äù*\n",
    "* Cosine similarity asks, *‚ÄúAre these vectors pointing in the same direction?‚Äù*\n",
    "\n",
    "This is especially useful in NLP, where the **direction** of a word vector captures meaning more reliably than its length.\n",
    "\n",
    "The cosine similarity score ranges from **-1 to 1**, with higher values indicating greater similarity. In practice, embeddings usually fall between **0 and 1**, since negative similarity (opposite meanings) is rare.\n",
    "\n",
    "Using `NumPy`, we can compute cosine similarity as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f446a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(vector1, vector2):\n",
    "    return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed541a",
   "metadata": {},
   "source": [
    "In this project, we‚Äôll use cosine similarity to score players‚Äô guesses in the word association game.\n",
    "\n",
    "\n",
    "## Part B: Training an Embedding Model\n",
    "\n",
    "Now that we understand how embeddings work, let‚Äôs train one ourselves using **Word2Vec** ‚Äî one of the earliest and most influential embedding techniques.\n",
    "\n",
    "Developed by **Tomas Mikolov** and his team at Google in 2013, Word2Vec learns to represent words as vectors based on the contexts in which they appear.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We‚Äôll use a collection of Wikipedia articles available through Hugging Face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3138093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import os\n",
    "\n",
    "MODEL_PATH = \"word2vec.model\"\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    # https://huggingface.co/datasets/wikimedia/wikipedia\n",
    "    dataset = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\", split=\"train\")\n",
    "\n",
    "    training_words = []\n",
    "\n",
    "    # Use the first 5,000 articles for demonstration\n",
    "    for article in dataset[\"text\"][:5000]:\n",
    "        for sent in sent_tokenize(article):\n",
    "            tokens = [word.lower() for word in word_tokenize(sent.lower())]\n",
    "            if tokens:\n",
    "                training_words.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8100d",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Note:** Real-world models are trained on billions of words. We use 5,000 articles here for simplicity and speed.\n",
    "\n",
    "### Training the Model\n",
    "\n",
    "We can now train a Word2Vec model using the **CBOW (Continuous Bag of Words)** approach via the `gensim` library. Each word will be represented as a 100-dimensional vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c1fe115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    from gensim.models import Word2Vec\n",
    "    model = Word2Vec.load(MODEL_PATH)\n",
    "else:\n",
    "    # Build a model using the CBOW approach\n",
    "    model = gensim.models.Word2Vec(\n",
    "        sentences=training_words,\n",
    "        vector_size=100,\n",
    "        window=5,\n",
    "        min_count=5,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811df0c0",
   "metadata": {},
   "source": [
    "After training, we can retrieve embeddings for any word (or token). The following function will help us visualize the embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "644df8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_embedding_heatmap(embeddings, labels=None, title=None, figsize=(12, 2), cmap=\"coolwarm\"):\n",
    "    # Handle 1D embeddings\n",
    "    if embeddings.ndim == 1:\n",
    "        embeddings = embeddings.reshape(1, -1)\n",
    "    \n",
    "    # Default labels\n",
    "    if labels is None:\n",
    "        labels = [f\"Item {i}\" for i in range(embeddings.shape[0])]\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(\n",
    "        embeddings,\n",
    "        cmap=cmap,\n",
    "        cbar_kws={'label': 'Value'},\n",
    "        xticklabels=10,          # show every 10th dimension\n",
    "        yticklabels=labels\n",
    "    )\n",
    "    plt.xlabel(\"Embedding Dimension\")\n",
    "    plt.ylabel(\"\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29720294",
   "metadata": {},
   "source": [
    "Let's turn the word *\"sun\"* into an embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c5dbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = \"sun\"\n",
    "sun_embedding = model.wv[word]\n",
    "plot_embedding_heatmap(sun_embedding, labels=[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406f2a24",
   "metadata": {},
   "source": [
    "Now, let's try comparing the word \"sun\" with \"moon\" and \"boat\" using both Euclidean distance and Cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bf3ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun - Moon\n",
      "Euclidean distance: 9.119643211364746\n",
      "Cosine similarity: 0.6887038350105286\n",
      "\n",
      "Sun - Boat\n",
      "Euclidean distance: 11.610834121704102\n",
      "Cosine similarity: 0.13132111728191376\n"
     ]
    }
   ],
   "source": [
    "moon_embedding = model.wv[\"moon\"]\n",
    "boat_embedding = model.wv[\"boat\"]\n",
    "\n",
    "print(\"Sun - Moon\")\n",
    "print(f\"Euclidean distance: {euclidean_distance(sun_embedding, moon_embedding)}\")\n",
    "print(f\"Cosine similarity: {cosine_sim(sun_embedding, moon_embedding)}\")\n",
    "print()\n",
    "print(\"Sun - Boat\")\n",
    "print(f\"Euclidean distance: {euclidean_distance(sun_embedding, boat_embedding)}\")\n",
    "print(f\"Cosine similarity: {cosine_sim(sun_embedding, boat_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4ffd62",
   "metadata": {},
   "source": [
    "As you can see, the Euclidean distance between *sun* and *moon* is **smaller** than between *sun* and *boat*. Furthermore, the cosine similarity between *sun* and *moon* is **larger** than between *sun* and *boat*. This means that the words *sun* and *moon* are semantically more related than *sun* and *boat* (as we would expect).\n",
    "\n",
    "We will use this in our game, where we score the guessed words based on Cosine similarity with the target word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52fcd5",
   "metadata": {},
   "source": [
    "## Part C: Building the Game\n",
    "\n",
    "Now that we understand embeddings and similarity, let‚Äôs apply this knowledge to build a **word associations game**.\n",
    "\n",
    "### Game Rules\n",
    "\n",
    "* You‚Äôre given a **target word**.\n",
    "* You enter four **associations** ‚Äî words you think are related.\n",
    "* Each guess is scored based on its **cosine similarity** to the target.\n",
    "* After four guesses, you receive a new target word.\n",
    "* If a guess is too dissimilar, you lose one **health point**.\n",
    "* The game ends after three lost health points.\n",
    "\n",
    "### Tech Stack\n",
    "\n",
    "* **Next.js** ‚Äî frontend framework\n",
    "* **Tailwind CSS** ‚Äî UI styling\n",
    "* **OpenAI Embedding Model (`text-embedding-3-small`)** ‚Äî used for real-time similarity scoring\n",
    "\n",
    "Although we trained our own model earlier, OpenAI‚Äôs embeddings are larger, faster, and better suited for interactive applications.\n",
    "\n",
    "### Choosing Target Words\n",
    "\n",
    "We‚Äôll use a list of 500 of the most common nouns from the [**Brown Corpus**](https://en.wikipedia.org/wiki/Brown_Corpus). Here‚Äôs how we generate and save them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca078c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/filip/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/filip/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved 500 nouns to nouns.json\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk import pos_tag\n",
    "from collections import Counter\n",
    "import nltk, json\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "words = brown.words()\n",
    "tagged = pos_tag(words)\n",
    "\n",
    "nouns = [w.lower() for w, pos in tagged if pos in ('NN', 'NNS')]\n",
    "freq_nouns = [w for w, _ in Counter(nouns).most_common(500)]\n",
    "\n",
    "with open(\"nouns.json\", \"w\") as f:\n",
    "    json.dump(freq_nouns, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Saved {len(freq_nouns)} nouns to nouns.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdebf938",
   "metadata": {},
   "source": [
    "We then use this `nouns.json` file as the source for our target words.\n",
    "\n",
    "## Final Result\n",
    "\n",
    "The completed game lets you explore how word meanings relate in vector space ‚Äî and turns semantic similarity into an interactive challenge.\n",
    "\n",
    "üëâ **You can try the game [here](https://semantiq.vercel.app/)!**\n",
    "\n",
    "**In summary:**\n",
    "This project combines theoretical NLP concepts with hands-on implementation, showing how embeddings and cosine similarity can power creative, language-driven applications. By gamifying these ideas, we make the abstract world of vectors tangible ‚Äî and fun."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantiq-nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
